{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6b785c",
   "metadata": {},
   "source": [
    "The function of this notebook is to load, clean and embed the dataframe to be used in the final model. The dataframe is then saved in a .csv file, which can be loaded in the final program. This achieves optimization in the final program and website deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce91ee95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings for cleaner output\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e790027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the combined dataframe: (67992, 10)\n",
      "                                                name       asins  \\\n",
      "0  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "1  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "2  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "3  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "4  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "\n",
      "                                          categories reviews.doRecommend  \\\n",
      "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "\n",
      "   reviews.numHelpful  reviews.rating  \\\n",
      "0                 0.0             5.0   \n",
      "1                 0.0             5.0   \n",
      "2                 0.0             5.0   \n",
      "3                 0.0             4.0   \n",
      "4                 0.0             5.0   \n",
      "\n",
      "                                        reviews.text  \\\n",
      "0  This product so far has not disappointed. My c...   \n",
      "1  great for beginner or experienced person. Boug...   \n",
      "2  Inexpensive tablet for him to use and learn on...   \n",
      "3  I've had my Fire HD 8 two weeks now and I love...   \n",
      "4  I bought this for my grand daughter when she c...   \n",
      "\n",
      "                             reviews.title  \\\n",
      "0                                   Kindle   \n",
      "1                                very fast   \n",
      "2  Beginner tablet for our 9 year old son.   \n",
      "3                                  Good!!!   \n",
      "4                Fantastic Tablet for kids   \n",
      "\n",
      "                                           imageURLs         meta_category  \n",
      "0  https://upload.wikimedia.org/wikipedia/commons...  Portable Electronics  \n",
      "1  https://upload.wikimedia.org/wikipedia/commons...  Portable Electronics  \n",
      "2  https://upload.wikimedia.org/wikipedia/commons...  Portable Electronics  \n",
      "3  https://upload.wikimedia.org/wikipedia/commons...  Portable Electronics  \n",
      "4  https://upload.wikimedia.org/wikipedia/commons...  Portable Electronics  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b46239b87dd440a985f3f074e749560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "# Import all necessary libraries for this program\n",
    "\n",
    "\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"datafiniti/consumer-reviews-of-amazon-products\")\n",
    "\n",
    "# Read CSV files\n",
    "file_path1 = os.path.join(path, \"1429_1.csv\")\n",
    "file_path2 = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
    "file_path3 = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "df3 = pd.read_csv(file_path3)\n",
    "\n",
    "# Load pickle mapping\n",
    "\n",
    "pickle_file_path = Path.cwd() / \"Joblib_files\" / \"unique_categories_dict.pkl\"\n",
    "if not pickle_file_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing pickle file: {pickle_file_path}\")\n",
    "with open(pickle_file_path, \"rb\") as f:\n",
    "    meta_category_mapping = pickle.load(f)\n",
    "\n",
    "# Filter and prepare data\n",
    "columns_df1 = ['name', 'asins', 'categories', 'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating', 'reviews.text', 'reviews.title']\n",
    "columns_other = columns_df1 + ['imageURLs']\n",
    "df1_filtered = df1[columns_df1]\n",
    "df1_filtered['imageURLs'] = \"https://upload.wikimedia.org/wikipedia/commons/a/ac/No_image_available.svg\"\n",
    "df2_filtered = df2[columns_other]\n",
    "df3_filtered = df3[columns_other]\n",
    "\n",
    "# Combine the dataframes, and map the meta-categories that we extracted via the clustering model to the 'categories' column\n",
    "df_combined = pd.concat([df1_filtered, df2_filtered, df3_filtered], ignore_index=True)\n",
    "df_combined['meta_category'] = df_combined['categories'].map(meta_category_mapping).fillna(\"Unknown\")\n",
    "\n",
    "# Print output of the combined dataframe\n",
    "print(\"Shape of the combined dataframe:\", df_combined.shape)\n",
    "print(df_combined.head())\n",
    "\n",
    "\n",
    "# First we need to clean the data with our data cleaning function, taking into account that the reviews.text column is a string but might contain floats\n",
    "# Clean the review text column and append the cleaned text to a new column, given the size of the dataset this will not increase the model runtime significantly\n",
    "def light_clean(text):\n",
    "    if isinstance(text, float):\n",
    "        text = str(text)  # Convert float to string\n",
    "    text = text.strip()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # normalize whitespace\n",
    "    return text\n",
    "\n",
    "df_combined[\"cleaned_text\"] = df_combined[\"reviews.text\"].apply(light_clean)\n",
    "\n",
    "# Then we convert the relevant columns of the dataframe to word embeddings using a pre-trained sentence transformer model. We use a sentence transformer as these are designed \n",
    "# to work well with natural, unaltered sentences and are trained on a large corpus of text data, making them suitable for generating embeddings for a wide range of text inputs.\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# Generate embeddings for the cleaned review text\n",
    "embeddings = model.encode(df_combined[\"cleaned_text\"].tolist(), show_progress_bar=True, convert_to_tensor= True, device='cuda')\n",
    "# Append the embeddings to the dataframe\n",
    "df_combined[\"embeddings\"] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9597e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined dataframe with embeddings to a CSV file\n",
    "output_file_path = Path.cwd() / \"Joblib_files\" / \"amazon_reviews_with_embeddings.csv\"\n",
    "df_combined.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded successfully, the OPENAI_TEST_KEY_KdR is: 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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Use the standard environment variable name for OpenAI API key\n",
    "api_key = os.getenv(\"OPENAI_TEST_KEY_KdR\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_TEST_KEY_KdR environment variable.\")\n",
    "\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "# Print the OpenAI API key to confirm it is loaded correctly (for debugging, remove in production)\n",
    "print(\"OpenAI API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296d9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the dataframes that contain the final model output into a single dataframe, that can be loaded into the website\n",
    "files_to_load = [\"Batteries_Summary.csv\", \"Connected_Home_Electronics.csv\", \"Kitchen_Storage_Summary.csv\", \n",
    "                  \"Office_Supplies_Summary.csv\", \"Pet_Products_Summary.csv\", \"Portable_Electronics.csv\"]\n",
    "\n",
    "# Load each file to load and concatenate them into a single dataframe\n",
    "dataframes = []\n",
    "for file_name in files_to_load:\n",
    "    file_path = Path.cwd() / \"Product Summaries\" / file_name\n",
    "    if not file_path.exists():\n",
    "        print(f\"File {file_name} does not exist, skipping.\")\n",
    "        continue\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "Summaries_df = pd.concat(dataframes, ignore_index=True)\n",
    "# Save the combined dataframe to a CSV file\n",
    "output_summaries_path = Path.cwd() / \"Product Summaries\" / \"Summaries Combined.csv\"\n",
    "Summaries_df.to_csv(output_summaries_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_image_url(url_string):\n",
    "    \"\"\"\n",
    "    Extract the best valid image URL from a comma-separated list.\n",
    "    Decodes URL-encoded parts, filters for known image hosts.\n",
    "    \"\"\"\n",
    "    placeholder = \"https://upload.wikimedia.org/wikipedia/commons/a/ac/No_image_available.svg\"\n",
    "    \n",
    "    if pd.isna(url_string) or not url_string.strip():\n",
    "        return placeholder\n",
    "\n",
    "    urls = [url.strip() for url in url_string.split(\",\") if url.strip()]\n",
    "    \n",
    "    trusted_domains = [\n",
    "        'amazon.com',\n",
    "        'ebayimg.com'\n",
    "    ]\n",
    "\n",
    "    for url in urls:\n",
    "        decoded_url = urllib.parse.unquote(url)\n",
    "        for domain in trusted_domains:\n",
    "            if domain in decoded_url:\n",
    "                return decoded_url  # return first valid match\n",
    "\n",
    "    # fallback if none matched\n",
    "    return placeholder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
