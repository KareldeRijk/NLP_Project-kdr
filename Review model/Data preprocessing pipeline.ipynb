{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bab8e3",
   "metadata": {},
   "source": [
    "In this notebook, we will train a lightweight LLM to generate a short article per product category. We will use llama mini (3B) with n-shotting and fine-tuning on our dataset as a first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0deb8bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karel\\AppData\\Local\\Temp\\ipykernel_77020\\2756058187.py:11: DtypeWarning: Columns (1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(file_path1)\n"
     ]
    }
   ],
   "source": [
    "# First we download the dataset from the kagglehub URL and save it to a dataframe\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"datafiniti/consumer-reviews-of-amazon-products\")\n",
    "\n",
    "\n",
    "# Download the datasets from the specified path, from previous notebook we know the shape of the data and the columns we are interested in\n",
    "file_path1 = os.path.join(path, \"1429_1.csv\")\n",
    "df1 = pd.read_csv(file_path1)\n",
    "file_path2 = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")\n",
    "df2 = pd.read_csv(file_path2)\n",
    "file_path3 = os.path.join(path, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "df3 = pd.read_csv(file_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa02232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-category mapping loaded successfully.\n",
      "{'AA,AAA,Electronics Features,Health,Electronics,Health & Household,Camcorder Batteries,Camera & Photo,Batteries,Household Batteries,Accessories,Camera Batteries,Health and Beauty,Household Supplies,Batteries & Chargers,Health, Household & Baby Care,Health Personal Care': 'Batteries', 'AA,AAA,Health,Electronics,Health & Household,Camcorder Batteries,Camera & Photo,Batteries,Household Batteries,Robot Check,Accessories,Camera Batteries,Health and Beauty,Household Supplies,Batteries & Chargers,Health, Household & Baby Care,Health Personal Care': 'Batteries', 'Accessories,USB Cables,Computers & Accessories,Computer Accessories & Peripherals,Electronics,Cables,Cables & Interconnects': 'Portable Electronics', 'Amazon Device Accessories,Kindle Store,Kindle Touch (4th Generation) Accessories,Kindle E-Reader Accessories,Covers,Kindle Touch (4th Generation) Covers': 'Portable Electronics', 'Amazon Devices & Accessories,Amazon Device Accessories,Power Adapters & Cables,Kindle Store,Kindle E-Reader Accessories,Kindle Paperwhite Accessories': 'Portable Electronics', 'Amazon Echo,Home Theater & Audio,MP3 MP4 Player Accessories,Electronics,Portable Audio,Compact Radios Stereos,Smart Hubs & Wireless Routers,Featured Brands,Smart Home & Connected Living,Home Security,Kindle Store,Electronic Components,Home Automation,Mobile Bluetooth Speakers,Home, Garage & Office,Amazon Tap,Home,Mobile Speakers,TVs & Electronics,Portable Bluetooth Speakers,Bluetooth & Wireless Speakers,Electronics Features,Frys,Speakers,Mobile,Digital Device 3,Smart Home,Home Improvement,Electronics, Tech Toys, Movies, Music,Smart Home & Home Automation Devices,Smart Hubs,MP3 Player Accessories,Home Safety & Security,Voice Assistants,Amazon Home,Alarms & Sensors,Portable Audio & Electronics,Amazon Devices,Audio,Bluetooth Speakers,MP3 Accessories,All Bluetooth & Wireless Speakers': 'Connected Home Electronics', 'Amazon Echo,Home Theater & Audio,MP3 MP4 Player Accessories,Smart Speakers,Electronics,Portable Audio,Compact Radios Stereos,Smart Hubs & Wireless Routers,Featured Brands,Smart Home & Connected Living,Home Security,Kindle Store,Electronic Components,Home Automation,Smart Speakers, Hubs & Accessories,Mobile Bluetooth Speakers,Home, Garage & Office,Amazon Tap,Home,Mobile Speakers,TVs & Electronics,Portable Bluetooth Speakers,Bluetooth & Wireless Speakers,Electronics Features,TV, Video & Home Audio,Frys,Media Streamers,Speakers,Mobile,Digital Device 3,Consumer Electronics,Smart Home,Home Improvement,Electronics, Tech Toys, Movies, Music,Smart Home & Home Automation Devices,Smart Hubs,MP3 Player Accessories,Home Safety & Security,Voice Assistants,Amazon Home,Alarms & Sensors,Surveillance & Smart Home Electronics,Portable Audio & Electronics,Amazon Devices,Audio,Bluetooth Speakers,MP3 Accessories,All Bluetooth & Wireless Speakers': 'Connected Home Electronics', 'Amazon Echo,Networking,Home & Tools,Smart Home Automation,Smart Speakers,Electronics,TVs Entertainment,New Networking,Smart Hub & Kits,Digital Device 3,Speakers & Audio Systems,Consumer Electronics,Wireless Speakers,See more Amazon Echo Spot Smart Assistant - Black,Smart Speakers, Hubs & Accessories,Home Improvement,Amazon Home,Surveillance & Smart Home Electronics,Virtual Assistant Speakers Displays,Home & Outdoors,Amazon,Bluetooth Speakers': 'Connected Home Electronics', 'Amazon Echo,See more Amazon Echo (1st Generation) Smart Assistant -...,Smart Speakers,Smart Speaker & Hub Accessories,Electronics,Digital Device 3,Consumer Electronics,Home Audio & Home Theater,Smart Speakers, Hubs & Accessories,Amazon Home,Surveillance & Smart Home Electronics,Amazon,Voice-Enabled Smart Assistants,Home Audio Speakers': 'Connected Home Electronics', 'Amazon Echo,Smart Home,Networking,Home & Tools,Home Improvement,Smart Home Automation,Voice Assistants,Amazon Home,Amazon,Smart Hub & Kits,Digital Device 3': 'Connected Home Electronics', 'Amazon Echo,Smart Speakers,Electronics,Digital Device 3,Home Audio & Home Theater,Consumer Electronics,Smart Home,Smart Speakers, Hubs & Accessories,Voice Assistants,Amazon Home,Surveillance & Smart Home Electronics,Amazon,Home Audio Speakers': 'Connected Home Electronics', 'Amazon Echo,Virtual Assistant Speakers,Electronics Features,Home & Tools,Smart Home Automation,TVs Entertainment,Speakers,Smart Hub & Kits,Digital Device 3,Wireless Speakers,Smart Home,Home Improvement,Voice Assistants,Amazon Home,Amazon': 'Connected Home Electronics', 'Amazon Echo,Virtual Assistant Speakers,Electronics Features,Networking,Home & Tools,Smart Home Automation,Electronics,TVs Entertainment,Speakers,New Networking,Smart Hub & Kits,Digital Device 3,Speakers & Audio Systems,Wireless Speakers,Smart Home,Home Improvement,Voice Assistants,Amazon Home,Virtual Assistant Speakers Displays,Home & Outdoors,Amazon,Bluetooth Speakers': 'Connected Home Electronics', 'Amazon SMP,Categories,Streaming Media Players,Electronics,Fire TV,Digital Device 4': 'Connected Home Electronics', 'Amazon SMP,Electronics Features,Kids & Family,TV, Video & Home Audio,Frys,Digital Device 4,Consumer Electronics,Kids Family,Video Games,Internet & Media Streamers,Streaming Media Players,Fire TV,Home Audio,Consoles': 'Connected Home Electronics', 'Amazon SMP,TV, Video & Home Audio,Electronics,Electronics Deals,TVs Entertainment,Digital Device 4,Tvs & Home Theater,Featured Brands,Video Devices & TV Tuners,Consumer Electronics,TV & Video,Internet & Media Streamers,Streaming Media Players,Fire TV,Streaming Devices,Amazon Devices,Amazon,See more Amazon Fire TV with Alexa Voice Remote Digital...': 'Connected Home Electronics', 'Audio & Video Accessories,AmazonBasics,Car Audio & Video Installation,Electronics Features,Speaker Cables,Wired Headsets & Speakers,Audio Cables,Electronics,Speakers,Cable Or Adapter,Cables & Interconnects,Consumer Electronics,Cases & Covers,Power & Speaker Wire,Accessories & Supplies,Vehicle Electronics & GPS': 'Connected Home Electronics', 'Audio & Video Accessories,TV, Video & Home Audio,Home Audio & Video Accessories,DVD Cases,Electronics,Media Cases & Storage,TV, Video & Audio Accessories,Media Storage & Organization,Disc Storage Wallets,Consumer Electronics,CD, DVD & Blu-ray Discs,Blank Audio/Video Media,Accessories & Supplies,all electronics': 'Connected Home Electronics', 'Back To College,College Electronics,College Tvs & Home Theater,Electronics,Tvs & Home Theater,Streaming Devices,Featured Brands,Amazon Devices,Holiday Shop,Ways To Shop,TV & Home Theater,Streaming Media Players,All Streaming Media Players,TVs Entertainment,Video Games,Kindle Store,Electronics Features,Kids & Family,Fire TV': 'Connected Home Electronics', 'Bags, Cases & Sleeves,Computers & Accessories,See more AmazonBasics 15.6 Inch Laptop And Tablet Bag -...,Electronics,Tablet Accessories,Accessories,Computers/Tablets & Networking,Messenger Bags,Bags,Laptop & Desktop Accessories,Laptop Cases & Bags,Laptop Accessories,Cases,computers,Backpacks': 'Portable Electronics', 'Carriers & Totes,Hard-Sided Carriers,Crates Kennels,Pet Supplies: International Shipping Available,Cat Supplies,Pet Supplies,Carriers & Crates,Custom Stores,Dog Supplies,Pet Products,Top Selection from AmazonPets': 'Pet Products', 'Cases,Kindle Store,Amazon Device Accessories,Accessories,Tablet Accessories': 'Portable Electronics', 'Streaming Media Players,Electronics': 'Connected Home Electronics', 'Chargers & Adapters,Computers & Accessories,Fire Tablet Accessories,Electronics,Power Adapters & Cables,Amazon Tablet Accessory,Amazon Device Accessories,Digital Device Accessory,Tablet Accessories,Kindle Fire (2nd Generation) Accessories,Kindle Store,Power Adapters Cables,Amazon Devices,Chargers Adapters': 'Portable Electronics', 'Chargers & Adapters,Computers & Accessories,Tablet & E-Reader Accessories,Amazon Devices & Accessories,Fire Tablet Accessories,Electronics,Power Adapters & Cables,Cell Phones,Amazon Device Accessories,Cell Phone Accessories,Cell Phone Batteries & Power,Tablet Accessories,Featured Brands,Kindle Fire (2nd Generation) Accessories,Kindle Store,Home Improvement,Fire (5th Generation) Accessories,Electrical,Amazon Devices,Home,Tablets & E-Readers,Cables & Chargers': 'Portable Electronics', 'Computers & Accessories,Computer Accessories & Peripherals,Electronics,Power Adapters & Cables,Amazon Book Reader Accessory,Digital Device Accessory,Cables & Interconnects,Tablet & eBook Reader Accs,Computers/Tablets & Networking,USB Cables,See more Amazon Kindle Fire 5-Feet Micro USB Cable - Wh...,Power Adapters Cables,Chargers & Sync Cables': 'Portable Electronics', 'Computers & Accessories,Electronics,Amazon Device Accessories,Digital Device Accessory,Abis Electronics,Tablet Accessories,Power Adapters': 'Portable Electronics', 'Computers & Accessories,Tablet & E-Reader Accessories,Amazon Devices & Accessories,Electronics,Power Adapters & Cables,Computers Features,Cell Phone Accessories,Cell Phone Batteries & Power,Digital Device Accessory,Tablet Accessories,Featured Brands,Kindle Fire (2nd Generation) Accessories,Kindle Store,Kindle Accessories,Power Adapters Cables,Electrical,Home,Tablets & E-Readers,Chargers Adapters,Chargers & Adapters,Electronics Features,Fire Tablet Accessories,Amazon Book Reader Accessory,Cell Phones,Amazon Device Accessories,Home Improvement,Fire (5th Generation) Accessories,Amazon Devices,Cables & Chargers': 'Portable Electronics', 'Computers & Accessories,Tablet & E-Reader Accessories,Amazon Devices & Accessories,Electronics,Power Adapters & Cables,Computers Features,Cell Phone Accessories,Cell Phone Batteries & Power,Digital Device Accessory,Tablet Accessories,Featured Brands,Kindle Fire (2nd Generation) Accessories,Kindle Store,Power Adapters Cables,Electrical,Home,Tablets & E-Readers,Chargers Adapters,Chargers & Adapters,Electronics Features,Fire Tablet Accessories,Amazon Book Reader Accessory,Cell Phones,Amazon Device Accessories,Home Improvement,Fire (5th Generation) Accessories,Amazon Devices,Cables & Chargers': 'Portable Electronics', 'Computers & Tablets,E-Readers & Accessories,eBook Readers,Kindle E-readers': 'Portable Electronics', 'Computers & Tablets,Tablets,All Tablets,Computers/Tablets & Networking,Tablets & eBook Readers,Fire Tablets,Frys': 'Portable Electronics', 'Computers,Amazon Echo,Virtual Assistant Speakers,Audio & Video Components,Electronics Features,Computer Accessories,Home & Tools,See more Amazon Echo Show Smart Assistant - White,Smart Home Automation,Electronics,TVs Entertainment,Speakers,Smart Hub & Kits,Digital Device 3,Consumer Electronics,Wireless Speakers,Home Improvement,Amazon Home,Amazon,Computer Speakers,Voice-Enabled Smart Assistants': 'Connected Home Electronics', 'Computers,Electronics Features,EBook Readers,Tablets,Electronics,Amazon Ereaders,iPad & Tablets,Kindle E-readers,iPad Accessories,Used:Tablets,E-Readers,E-Readers & Accessories,Computers/Tablets & Networking,Used:Computers Accessories,iPads Tablets,All Tablets,Tablets & E-readers,Amazon Book Reader,Computers & Tablets,Amazon,Tablets & eBook Readers': 'Portable Electronics', 'Computers,Electronics Features,Tablets,Electronics,iPad & Tablets,Kindle E-readers,iPad Accessories,Used:Tablets,E-Readers,E-Readers & Accessories,Computers/Tablets & Networking,Used:Computers Accessories,iPads Tablets,All Tablets,Tablets & E-readers,Computers & Tablets,Amazon,Tablets & eBook Readers': 'Portable Electronics', \"Computers,Fire Tablets,Electronics Features,Computer Accessories,Tablets,Top Rated,Amazon Tablets,Electronics,Kids' Tablets,iPad & Tablets,Cases & Bags,Electronics, Tech Toys, Movies, Music,Computers & Tablets\": 'Portable Electronics', 'Computers/Tablets & Networking,Tablet & eBook Reader Accs,Chargers & Sync Cables,Power Adapters & Cables,Kindle Store,Amazon Device Accessories,Fire Tablet Accessories,Kindle Fire (2nd Generation) Accessories': 'Portable Electronics', 'Computers/Tablets & Networking,Tablets & eBook Readers,Computers & Tablets,Tablets,All Tablets': 'Portable Electronics', 'Computers/Tablets & Networking,Tablets & eBook Readers,Electronics,eBook Readers & Accessories,eBook Readers': 'Portable Electronics', 'Consumer Electronics,Amazon Echo,Electronics Features,MP3 MP4 Player Accessories,Amazon Home,Voice-Enabled Smart Assistants,Digital Device 3': 'Portable Electronics', 'Consumer Electronics,Amazon Echo,Smart Speakers, Hubs & Accessories,Smart Speakers,Amazon Home,Surveillance & Smart Home Electronics,Digital Device 3': 'Connected Home Electronics', 'Crate Training,Crates Kennels,Pet Supplies,Dogs,City Sniffers,Custom Stores,Dog Supplies,Top Selection from AmazonPets,Pet Products,Cages & Crates,See more AmazonBasics Double Door Folding Metal Dog Cra...': 'Pet Products', 'Crate Training,Crates Kennels,Pet Supplies,Why Keep Them Waiting Prime Free Two-Day Shipping,Custom Stores,Dog Supplies,Pet Products,Top Selection from AmazonPets,Cages & Crates,Crates & Kennels': 'Pet Products', 'E-Readers & Accessories,EBook Readers,Amazon Book Reader,Computers & Tablets,Amazon Ereaders,Kindle E-readers,E-Readers': 'Portable Electronics', 'EBook Readers,Tablets,Electronics,Amazon Ereaders,Kindle E-readers,E-Readers,Featured Brands,E-Readers & Accessories,Amazon Book Reader,Computers & Tablets,Amazon Devices,Amazon,Tablets & E-Readers': 'Portable Electronics', 'Electronics Features,Computers & Accessories,Computer Accessories & Peripherals,Keyboards,Electronics,Amazon Device Accessories,Digital Device Accessory,Keyboards, Mice & Accessories,Tablet Accessories,14701001': 'Portable Electronics', 'Electronics Features,Drives, Storage & Blank Media,Hard Drive Pouches,Computers & Accessories,Computer Accessories & Peripherals,Hard Drive Accessories,Electronics,Computers Features,Personal Computer,Accessories,Hard Drive Bags Cases,Computers/Tablets & Networking,Drive Enclosures & Docks,Laptop & Desktop Accessories,Hard Drive Bags & Cases,Carrying Case Or Bag': 'Portable Electronics', 'Electronics Features,Fire Tablets,Computers & Tablets,Tablets,All Tablets,Computers/Tablets & Networking,Tablets & eBook Readers': 'Portable Electronics', 'Electronics,Amazon Device Accessories,Kindle Store,Covers,Kindle E-Reader Accessories,Kindle DX (2nd Generation, Global Wireless) Accessories': 'Portable Electronics', 'Electronics,Categories,Fire TV,Kindle Store': 'Portable Electronics', 'Electronics,Categories,Streaming Media Players,Amazon Devices': 'Portable Electronics', \"Electronics,Computers,Computer Accessories,Cases & Bags,Fire Tablets,Electronics Features,Tablets,Computers & Tablets,Kids' Tablets,Electronics, Tech Toys, Movies, Music,iPad & Tablets,Top Rated\": 'Portable Electronics', 'Electronics,TVs Entertainment,Featured Brands,Other TV, Video & Audio Accs,College Tvs & Home Theater,Streaming Media Players,Fire TV,TVs Entertainment xbqxrzdteyyb,Ways To Shop,Amazon SMP,Electronics Features,TVs & Home Theater,TV, Video & Home Audio,On To College,Media Streamers,TV & Home Theater,TV, Video & Audio Accessories,Digital Device 4,All Streaming Media Players,College Electronics,Video Devices & TV Tuners,Consumer Electronics,TV & Video,Streaming Devices,Back To College,Amazon Devices,Amazon,Holiday Shop': 'Connected Home Electronics', 'Electronics,Tablets & E-Readers,Tablets,Back To College,College Electronics,College Ipads & Tablets,Featured Brands,Amazon Devices,Electronics Deals,Computers & Tablets,All Tablets,Electronics Features,eBook Readers': 'Portable Electronics', 'Electronics,eBook Readers & Accessories,Covers,Kindle Store,Amazon Device Accessories,Kindle E-Reader Accessories,Kindle (5th Generation) Accessories,Kindle (5th Generation) Covers': 'Portable Electronics', 'Electronics,eBook Readers & Accessories,Power Adapters,Computers/Tablets & Networking,Tablet & eBook Reader Accs,Chargers & Sync Cables,Power Adapters & Cables,Kindle Store,Amazon Device Accessories,Kindle Fire (2nd Generation) Accessories,Fire Tablet Accessories': 'Portable Electronics', 'Electronics,iPad & Tablets,All Tablets,Computers & Tablets,Tablets,eBook Readers': 'Portable Electronics', 'Electronics,iPad & Tablets,All Tablets,Computers/Tablets & Networking,Tablets & eBook Readers,Computers & Tablets,E-Readers & Accessories,E-Readers,Used:Computers Accessories,Used:Tablets,Computers,iPads Tablets,Kindle E-readers,Electronics Features': 'Portable Electronics', 'Electronics,iPad & Tablets,All Tablets,Fire Tablets,Tablets,Computers & Tablets': 'Portable Electronics', 'Featured Brands,E-Readers & Accessories,EBook Readers,Tablets,Amazon Book Reader,Electronics,Computers & Tablets,Amazon Ereaders,Kindle E-readers,Amazon Devices,Tablets & E-Readers,E-Readers': 'Portable Electronics', 'Featured Brands,Electronics,Amazon Devices,Home,Home Improvement,Home Safety & Security,Home Security,Alarms & Sensors,Smart Home & Home Automation Devices,Mobile,Mobile Speakers,Mobile Bluetooth Speakers,Smart Hubs & Wireless Routers,Smart Hubs,Home, Garage & Office,Smart Home,Voice Assistants,Smart Home & Connected Living,Amazon Tap,Portable Audio,MP3 Accessories,Speakers,Amazon Echo,Electronics Features,TVs & Electronics,Portable Audio & Electronics,MP3 Player Accessories,Home Theater & Audio,Kindle Store,Frys,Electronic Components,Home Automation,Electronics, Tech Toys, Movies, Music,Audio,Bluetooth Speakers': 'Portable Electronics', 'Fire Tablets,Android Tablets,Tablets,All Tablets,Amazon Tablets,Electronics,Computers & Tablets,iPad & Tablets': 'Portable Electronics', 'Fire Tablets,Computers,Tablets,All Tablets,Amazon Tablets,Computer Components,Electronics,Hard Drives & Storage,Computers & Tablets': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Android Tablets,Tablets,All Tablets,Amazon Tablets,Electronics,Computers & Tablets,iPad & Tablets,Amazon,Tablets & eBook Readers,Tablets & E-Readers': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Electronics Features,Tablets,All Tablets,Amazon Tablets,Computers & Tablets,Electronics,iPad & Tablets,Tablets & eBook Readers': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Tablets,All Tablets,Amazon Tablets,Computers & Tablets,Electronics,Amazon,Tablets & eBook Readers': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Tablets,All Tablets,Amazon Tablets,Computers & Tablets,Electronics,Amazon,Tablets & eBook Readers,Tablets & E-Readers': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Tablets,All Tablets,Amazon Tablets,Computers & Tablets,Other Computers & Networking': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Tablets,All Tablets,Amazon Tablets,Computers & Tablets,Tablets & eBook Readers': 'Portable Electronics', 'Fire Tablets,Computers/Tablets & Networking,Tablets,All Tablets,Amazon Tablets,Frys,Computers & Tablets,Tablets & eBook Readers': 'Portable Electronics', \"Fire Tablets,Computers/Tablets & Networking,Walmart for Business,Tablets,Amazon Tablets,Tablets & E-readers,Kids' Tablets,Electronics,Computers & Tablets,Office Electronics,Amazon,Tablets & eBook Readers\": 'Portable Electronics', \"Fire Tablets,Learning Toys,Toys,Tablets,Amazon Tablets,Electronics, Tech Toys, Movies, Music,Computers & Tablets,Kids' Tablets,Electronics,iPad & Tablets,Tablets for Kids\": 'Portable Electronics', 'Fire Tablets,Tablets,All Tablets,Amazon Tablets': 'Portable Electronics', 'Fire Tablets,Tablets,All Tablets,Amazon Tablets,Computers & Tablets': 'Portable Electronics', 'Fire Tablets,Tablets,All Tablets,Amazon Tablets,Genuine Tablet Accessories,Computers & Tablets,Electronics,Amazon': 'Portable Electronics', \"Fire Tablets,Tablets,Amazon Tablets,Computers & Tablets,Kids' Tablets\": 'Portable Electronics', 'Fire Tablets,Tablets,Computers & Tablets,All Tablets': 'Portable Electronics', 'Fire Tablets,Tablets,Computers & Tablets,All Tablets,Computers/Tablets & Networking,Tablets & eBook Readers': 'Portable Electronics', 'Fire Tablets,Tablets,Computers & Tablets,All Tablets,Electronics, Tech Toys, Movies, Music,Electronics,iPad & Tablets,Android Tablets,Frys': 'Portable Electronics', 'Fire Tablets,Tablets,Computers & Tablets,All Tablets,Frys': 'Portable Electronics', 'Fire Tablets,Tablets,Computers/Tablets & Networking,Other Computers & Networking,Computers & Tablets,All Tablets': 'Portable Electronics', 'Frys,Software & Books,eReaders & Accessories,Tablet Cases Covers,Tablet Accessories,Computer Accessories': 'Portable Electronics', 'Home & Garden,Kitchen Storage & Organization,Kitchen, Dining & Bar,Kitchen & Dining Features,Food Storage,Racks & Holders,Kitchen & Dining,Home Kitchen Features,Home & Kitchen Features,Home & Kitchen,Kitchen,Coffee Pod Holders,Kitchen Dining Features,Storage & Organization': 'Kitchen Storage', 'Home & Garden,Oven Mitts & Potholders,Kitchen, Dining & Bar,Cookware,Kitchen,Home & Kitchen,Cookware Accessories,Linens & Textiles,Kitchen & Dining': 'Kitchen Storage', 'Kindle E-readers,Electronics Features,Computers & Tablets,E-Readers & Accessories,E-Readers,eBook Readers': 'Portable Electronics', 'Kindle Store,Amazon Devices,Electronics': 'Portable Electronics', 'Kindle Store,Categories,eBook Readers & Accessories,Fire TV Accessories,Electronics,Power Adapters & Cables,Amazon Device Accessories,Power Adapters': 'Portable Electronics', 'Laptop Computer Stands,Electronics Features,Stands, Holders & Car Mounts,Home Office Furniture,Electronics,Office & School Supplies,Computers Features,Personal Computer,Office Furniture & Lighting,Furniture,Office Products,Desk Accessories & Workspace Organizers,Office Furniture Lighting,Computer Add On,Stands,Computers/Tablets & Networking,Platforms, Stands & Shelves,Laptop & Desktop Accessories,Laptop Cases & Bags,Notebook Computer Stands': 'Office Supplies', 'Office,File Jackets & File Pockets,File Folders & Accessories,Files & Supplies,Office Solutions,Office Supplies,Office Product,Business & Industrial,Office & School Supplies,Expanding File Jackets Pockets,Smead,Office Products,File & Folder Accessories,Filing, Storage & Binding,Accessories,Expanding Files,See more File Pocket Expanding Folder Office Organizer ...,Filing Products,Expanding Wallets,Filing & Organizers,Expanding File Jackets & Pockets': 'Office Supplies', 'Office,eBook Readers,Electronics Features,Walmart for Business,Tablets,Electronics,Amazon Ereaders,Office Electronics,iPad & Tablets,Kindle E-readers,All Tablets,Amazon Book Reader,Computers & Tablets': 'Office Supplies', 'Portable Computer Accessories,Bags, Cases & Sleeves,Accessories,Computers & Accessories,Laptop Accessories,Electronics,Backpacks': 'Portable Electronics', 'Portable Computer Accessories,Bags, Cases & Sleeves,Accessories,Sleeves,Computers & Accessories,Laptop Accessories,Electronics,computers': 'Portable Electronics', 'Power Adapters & Cables,Electronics,USB Cables': 'Portable Electronics', 'Rice Dishes,Ready Meals,Beauty,Moisturizers,Lotions': 'Kitchen Storage', 'Standard Litter Boxes,Litter Boxes,Cat Supplies,Pet Supplies,Top Cat Supplies,Pet Products': 'Pet Products', 'Stereos,Remote Controls,Amazon Echo,Audio Docks & Mini Speakers,Amazon Echo Accessories,Kitchen & Dining Features,Speaker Systems,Electronics,TVs Entertainment,Clearance,Smart Hubs & Wireless Routers,Featured Brands,Wireless Speakers,Smart Home & Connected Living,Home Security,Kindle Store,Home Automation,Home, Garage & Office,Home,Voice-Enabled Smart Assistants,Virtual Assistant Speakers,Portable Audio & Headphones,Electronics Features,Amazon Device Accessories,iPod, Audio Player Accessories,Home & Furniture Clearance,Consumer Electronics,Smart Home,Surveillance,Home Improvement,Smart Home & Home Automation Devices,Smart Hubs,Home Safety & Security,Voice Assistants,Alarms & Sensors,Amazon Devices,Audio,Holiday Shop': 'Connected Home Electronics', 'Stereos,Remote Controls,Audio Docks & Mini Speakers,Kitchen & Dining Features,Home & Tools,Electronics,New Networking,Wireless Speakers,Home, Garage & Office,Portable Speakers,iPod, Audio Player Accessories,Smart Home,Surveillance,Home Improvement,Smart Home & Home Automation Devices,Alarms & Sensors,Amazon Devices,Amazon,Holiday Shop,Kitchen Dining Features,Amazon Echo,Amazon Echo Accessories,Networking,Speaker Systems,TVs Entertainment,Clearance,Smart Hubs & Wireless Routers,Featured Brands,Smart Home & Connected Living,Home Security,Kindle Store,Home Automation,Home,Voice-Enabled Smart Assistants,Virtual Assistant Speakers,Portable Audio & Headphones,Electronics Features,Smart Home Automation,Amazon Device Accessories,Speakers,Smart Hub & Kits,Digital Device 3,Home & Furniture Clearance,Consumer Electronics,Smart Hubs,Home Safety & Security,Voice Assistants,Amazon Home,Virtual Assistant Speakers Displays,Audio': 'Connected Home Electronics', 'TVs Entertainment,Wireless Speakers,Virtual Assistant Speakers,Featured Brands,Electronics,Amazon Devices,Home,Home Improvement,Home Safety & Security,Home Security,Alarms & Sensors,Smart Home & Home Automation Devices,Smart Hubs & Wireless Routers,Smart Hubs,Consumer Electronics,Voice-Enabled Smart Assistants,Smart Home & Connected Living,Home, Garage & Office,Smart Home,Voice Assistants,Surveillance,Home Automation,Speakers,Electronics Features,Holiday Shop,TV, Video & Home Audio,Internet & Media Streamers,Amazon Echo,Hubs & Controllers': 'Connected Home Electronics', 'Tablet & eBook Reader Accs,Consumer Electronics,Computers/Tablets & Networking,eBook Readers & Accessories,Electronics,Amazon Book Reader Accessory,Amazon Device Accessories,Other Multipurpose Batteries,Chargers & Sync Cables,Digital Device Accessory,Power Adapters': 'Portable Electronics', 'Tablets,Fire Tablets,Computers & Tablets,All Tablets': 'Portable Electronics', 'Tablets,Fire Tablets,Electronics,Computers,Computer Components,Hard Drives & Storage,Computers & Tablets,All Tablets': 'Portable Electronics', 'Tablets,Fire Tablets,Electronics,iPad & Tablets,Android Tablets,Computers & Tablets,All Tablets': 'Portable Electronics', 'Walmart for Business,Office Electronics,Tablets,Electronics,iPad & Tablets,All Tablets,Computers & Tablets,E-Readers & Accessories,Kindle E-readers,Electronics Features,eBook Readers,See more Amazon Kindle Voyage (Wi-Fi),See more Amazon Kindle Voyage 4GB, Wi-Fi  3G (Unlocked...': 'Office Supplies', 'Walmart for Business,Office Electronics,Tablets,Office,Electronics,iPad & Tablets,Windows Tablets,All Windows Tablets,Computers & Tablets,E-Readers & Accessories,E-Readers,eBook Readers,Kindle E-readers,Computers/Tablets & Networking,Tablets & eBook Readers,Electronics Features,Books & Magazines,Book Accessories,eReaders,TVs & Electronics,Computers & Laptops,Tablets & eReaders': 'Office Supplies', 'eBook Readers,E-Readers & Accessories,Amazon Book Reader,Computers & Tablets,Amazon Ereaders,Kindle E-readers': 'Portable Electronics', 'eBook Readers,E-Readers & Accessories,Amazon Book Reader,Computers & Tablets,Amazon Ereaders,Kindle E-readers,E-Readers': 'Portable Electronics', 'eBook Readers,E-Readers & Accessories,Electronics Features,Amazon Book Reader,Computers & Tablets,Amazon Ereaders,Kindle E-readers,E-Readers': 'Portable Electronics', 'eBook Readers,Electronics Features,Walmart for Business,Tablets,See more Amazon Kindle Voyage (Wi-Fi),Electronics,Amazon Ereaders,Office Electronics,iPad & Tablets,Kindle E-readers,E-Readers & Accessories,All Tablets,See more Amazon Kindle Voyage 4GB, Wi-Fi  3G (Unlocked...,Amazon Book Reader,Computers & Tablets': 'Portable Electronics', 'eBook Readers,Electronics Features,Walmart for Business,Tablets,See more Amazon Kindle Voyage (Wi-Fi),Electronics,Office Electronics,iPad & Tablets,Kindle E-readers,E-Readers & Accessories,All Tablets,See more Amazon Kindle Voyage 4GB, Wi-Fi  3G (Unlocked...,Computers & Tablets': 'Portable Electronics', 'eBook Readers,Fire Tablets,Electronics Features,Tablets,Amazon Tablets,College Ipads & Tablets,Electronics,Electronics Deals,College Electronics,Featured Brands,All Tablets,Computers & Tablets,Back To College,Amazon Devices,Tablets & E-Readers': 'Portable Electronics', 'eBook Readers,Kindle E-readers,Computers & Tablets,E-Readers & Accessories,E-Readers': 'Portable Electronics'}\n"
     ]
    }
   ],
   "source": [
    "# Import pickle dictionary to apply our meta-category mapping to the dataframes once these are merged\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "# Load the meta-category mapping from the pickle file\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "pickle_file_path = parent_dir / \"Clustering model\" / \"unique_categories_dict.pkl\"\n",
    "\n",
    "with open(pickle_file_path, \"rb\") as f:\n",
    "    meta_category_mapping = pickle.load(f)\n",
    "print(\"Meta-category mapping loaded successfully.\")\n",
    "print(meta_category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c01ad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df1: Index(['id', 'name', 'asins', 'brand', 'categories', 'keys', 'manufacturer',\n",
      "       'reviews.date', 'reviews.dateAdded', 'reviews.dateSeen',\n",
      "       'reviews.didPurchase', 'reviews.doRecommend', 'reviews.id',\n",
      "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
      "       'reviews.text', 'reviews.title', 'reviews.userCity',\n",
      "       'reviews.userProvince', 'reviews.username'],\n",
      "      dtype='object')\n",
      "Columns in df2: Index(['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand',\n",
      "       'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer',\n",
      "       'manufacturerNumber', 'reviews.date', 'reviews.dateAdded',\n",
      "       'reviews.dateSeen', 'reviews.doRecommend', 'reviews.id',\n",
      "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
      "       'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs'],\n",
      "      dtype='object')\n",
      "Columns in df3: Index(['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand',\n",
      "       'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer',\n",
      "       'manufacturerNumber', 'reviews.date', 'reviews.dateSeen',\n",
      "       'reviews.didPurchase', 'reviews.doRecommend', 'reviews.id',\n",
      "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
      "       'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print the columns of the dataframes\n",
    "print(\"Columns in df1:\", df1.columns)\n",
    "print(\"Columns in df2:\", df2.columns)\n",
    "print(\"Columns in df3:\", df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d063d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the combined dataframe: (67992, 9)\n",
      "Head of the combined dataframe:\n",
      "                                                name       asins  \\\n",
      "0  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "1  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "2  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "3  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "4  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...  B01AHB9CN2   \n",
      "\n",
      "                                          categories reviews.doRecommend  \\\n",
      "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...                True   \n",
      "\n",
      "   reviews.numHelpful  reviews.rating  \\\n",
      "0                 0.0             5.0   \n",
      "1                 0.0             5.0   \n",
      "2                 0.0             5.0   \n",
      "3                 0.0             4.0   \n",
      "4                 0.0             5.0   \n",
      "\n",
      "                                        reviews.text  \\\n",
      "0  This product so far has not disappointed. My c...   \n",
      "1  great for beginner or experienced person. Boug...   \n",
      "2  Inexpensive tablet for him to use and learn on...   \n",
      "3  I've had my Fire HD 8 two weeks now and I love...   \n",
      "4  I bought this for my grand daughter when she c...   \n",
      "\n",
      "                             reviews.title         meta_category  \n",
      "0                                   Kindle  Portable Electronics  \n",
      "1                                very fast  Portable Electronics  \n",
      "2  Beginner tablet for our 9 year old son.  Portable Electronics  \n",
      "3                                  Good!!!  Portable Electronics  \n",
      "4                Fantastic Tablet for kids  Portable Electronics  \n"
     ]
    }
   ],
   "source": [
    "# Columns to keep \n",
    "columns_to_keep = ['name', 'asins', 'categories',  'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating', 'reviews.text', 'reviews.title']\n",
    "\n",
    "# Filter the dataframes to keep only the relevant columns\n",
    "df1_filtered = df1[columns_to_keep]\n",
    "df2_filtered = df2[columns_to_keep]\n",
    "df3_filtered = df3[columns_to_keep]\n",
    "# Concatenate the filtered dataframes\n",
    "df_combined = pd.concat([df1_filtered, df2_filtered, df3_filtered], ignore_index=True)\n",
    "# Append df_combined with the meta-category mapping \n",
    "df_combined['meta_category'] = df_combined['categories'].map(meta_category_mapping)\n",
    "\n",
    "# Print the shape and the head of the combined dataframe\n",
    "print(\"Shape of the combined dataframe:\", df_combined.shape)\n",
    "print(\"Head of the combined dataframe:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a733ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product so far has not disappointed. My c...</td>\n",
       "      <td>this product so far has not disappointed my ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great for beginner or experienced person. Boug...</td>\n",
       "      <td>great for beginner or experienced person bough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inexpensive tablet for him to use and learn on...</td>\n",
       "      <td>inexpensive tablet for him to use and learn on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've had my Fire HD 8 two weeks now and I love...</td>\n",
       "      <td>i ve had my fire hd 8 two weeks now and i love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I bought this for my grand daughter when she c...</td>\n",
       "      <td>i bought this for my grand daughter when she c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  This product so far has not disappointed. My c...   \n",
       "1  great for beginner or experienced person. Boug...   \n",
       "2  Inexpensive tablet for him to use and learn on...   \n",
       "3  I've had my Fire HD 8 two weeks now and I love...   \n",
       "4  I bought this for my grand daughter when she c...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  this product so far has not disappointed my ch...  \n",
       "1  great for beginner or experienced person bough...  \n",
       "2  inexpensive tablet for him to use and learn on...  \n",
       "3  i ve had my fire hd 8 two weeks now and i love...  \n",
       "4  i bought this for my grand daughter when she c...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Drop rows with missing review text or rating\n",
    "df_combined = df_combined.dropna(subset=[\"reviews.text\", \"reviews.rating\"])\n",
    "\n",
    "# Clean the review text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)  # remove HTML tags\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # remove extra whitespace\n",
    "    return text.strip()\n",
    "\n",
    "df_combined[\"cleaned_text\"] = df_combined[\"reviews.text\"].apply(clean_text)\n",
    "print(\"✅ Cleaned data\")\n",
    "df_combined[[\"reviews.text\", \"cleaned_text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1cbe384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569fcb7ddc4942fdbce31fb8fdec0630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pre-trained SentenceTransformer model to generate embeddings for the cleaned review text\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# Generate embeddings for the cleaned review text\n",
    "embeddings = model.encode(df_combined[\"cleaned_text\"].tolist(), show_progress_bar=True, convert_to_tensor= True, device='cuda')\n",
    "# Add the embeddings to the dataframe\n",
    "df_combined[\"embeddings\"] = embeddings.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e5772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fef1a2648dd4f5f845ca0e13ddc9c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\karel\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3537e13b1544dd79dcee27e6537af2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99316f4439244937942ac1ee0af873a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547a9ca02b42446da90007bba4e2fb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      4\u001b[39m absa_pipeline = pipeline(\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msentiment-analysis\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33myangheng/deberta-v3-base-absa-v1.1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     tokenizer=DistilBertTokenizer.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mdistilbert-base-uncased\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Apply the ABSA pipeline to the cleaned review text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m absa_results = \u001b[43mabsa_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_combined\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcleaned_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Add the ABSA results to the dataframe\u001b[39;00m\n\u001b[32m     14\u001b[39m df_combined[\u001b[33m\"\u001b[39m\u001b[33mabsa_results\u001b[39m\u001b[33m\"\u001b[39m] = absa_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m inputs = (inputs,)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    161\u001b[39m _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\base.py:1412\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1409\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1410\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1411\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m    124\u001b[39m item = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterator)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\base.py:1338\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1337\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text_classification.py:190\u001b[39m, in \u001b[36mTextClassificationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters.keys():\n\u001b[32m    189\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:1089\u001b[39m, in \u001b[36mDebertaV2ForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1081\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1082\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1084\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1085\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1100\u001b[39m encoder_layer = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1101\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(encoder_layer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:796\u001b[39m, in \u001b[36mDebertaV2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    786\u001b[39m     token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m    788\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    789\u001b[39m     input_ids=input_ids,\n\u001b[32m    790\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m    794\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    803\u001b[39m encoded_layers = encoder_outputs[\u001b[32m1\u001b[39m]\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.z_steps > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:669\u001b[39m, in \u001b[36mDebertaV2Encoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[39m\n\u001b[32m    659\u001b[39m     output_states, attn_weights = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    660\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    661\u001b[39m         next_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    666\u001b[39m         output_attentions,\n\u001b[32m    667\u001b[39m     )\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m     output_states, attn_weights = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    679\u001b[39m     all_attentions = all_attentions + (attn_weights,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:437\u001b[39m, in \u001b[36mDebertaV2Layer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    430\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    435\u001b[39m     output_attentions: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    436\u001b[39m ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     attention_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m    446\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:370\u001b[39m, in \u001b[36mDebertaV2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    363\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m     rel_embeddings=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    369\u001b[39m ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m     self_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    379\u001b[39m         query_states = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:250\u001b[39m, in \u001b[36mDisentangledSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.relative_attention:\n\u001b[32m    249\u001b[39m     rel_embeddings = \u001b[38;5;28mself\u001b[39m.pos_dropout(rel_embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     rel_att = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisentangled_attention_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rel_att \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    255\u001b[39m     attention_scores = attention_scores + rel_att\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:341\u001b[39m, in \u001b[36mDisentangledSelfAttention.disentangled_attention_bias\u001b[39m\u001b[34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[39m\n\u001b[32m    333\u001b[39m scale = scaled_size_sqrt(pos_query_layer, scale_factor)\n\u001b[32m    334\u001b[39m r_pos = build_rpos(\n\u001b[32m    335\u001b[39m     query_layer,\n\u001b[32m    336\u001b[39m     key_layer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    339\u001b[39m     \u001b[38;5;28mself\u001b[39m.position_buckets,\n\u001b[32m    340\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m p2c_pos = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mr_pos\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43matt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matt_span\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m p2c_att = torch.bmm(key_layer, pos_query_layer.transpose(-\u001b[32m1\u001b[39m, -\u001b[32m2\u001b[39m))\n\u001b[32m    343\u001b[39m p2c_att = torch.gather(\n\u001b[32m    344\u001b[39m     p2c_att,\n\u001b[32m    345\u001b[39m     dim=-\u001b[32m1\u001b[39m,\n\u001b[32m    346\u001b[39m     index=p2c_pos.squeeze(\u001b[32m0\u001b[39m).expand([query_layer.size(\u001b[32m0\u001b[39m), key_layer.size(-\u001b[32m2\u001b[39m), key_layer.size(-\u001b[32m2\u001b[39m)]),\n\u001b[32m    347\u001b[39m ).transpose(-\u001b[32m1\u001b[39m, -\u001b[32m2\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use an ABSA model from Hugging Face with DistilBertTokenizer\n",
    "absa_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"yangheng/deberta-v3-base-absa-v1.1\"\n",
    ")\n",
    "\n",
    "# Apply the ABSA pipeline to the cleaned review text \n",
    "absa_results = absa_pipeline(df_combined[\"cleaned_text\"].tolist())\n",
    "\n",
    "# Add the ABSA results to the dataframe\n",
    "df_combined[\"absa_results\"] = absa_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
