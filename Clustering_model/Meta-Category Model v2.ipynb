{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68212344",
   "metadata": {},
   "source": [
    "In this notebook, we will train a model on the dataset created in the Transforming Meta-Categories notebook. The dataset contains product category labels (X) and a labeled Meta-Category (Y). The purpose of this model is to be able to recognize a product, and tell into which Meta-Category it belongs. We will try two different models: TF-IDF with Naive Bayes and TF-IDF with Logistic Regression. Further, we will use cross-validation to divide the dataset more evenly, following the results from v1 of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a789f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# Define the path to the directory containing the Excel files\n",
    "path = os.getcwd()\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "\n",
    "training_data_file = parent_dir / \"Spreadsheets\" / \"merged_dataset_with_meta_category.csv\"\n",
    "# Load the training data file\n",
    "training_data = pd.read_csv(training_data_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8a85b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Sample:\n",
      "                                              name_x  \\\n",
      "0  AmazonBasics AA Performance Alkaline Batteries...   \n",
      "1  AmazonBasics AA Performance Alkaline Batteries...   \n",
      "2  AmazonBasics AA Performance Alkaline Batteries...   \n",
      "3  AmazonBasics AA Performance Alkaline Batteries...   \n",
      "4  AmazonBasics AA Performance Alkaline Batteries...   \n",
      "\n",
      "                                            category primary_category name_y  \\\n",
      "0  AA,AAA,Electronics Features,Health,Electronics...  Health & Beauty    NaN   \n",
      "1  AA,AAA,Electronics Features,Health,Electronics...  Health & Beauty    NaN   \n",
      "2  AA,AAA,Electronics Features,Health,Electronics...  Health & Beauty    NaN   \n",
      "3  AA,AAA,Electronics Features,Health,Electronics...  Health & Beauty    NaN   \n",
      "4  AA,AAA,Electronics Features,Health,Electronics...  Health & Beauty    NaN   \n",
      "\n",
      "  Meta-Category Meta-Category2  \n",
      "0     Batteries      Batteries  \n",
      "1     Batteries      Batteries  \n",
      "2     Batteries      Batteries  \n",
      "3     Batteries      Batteries  \n",
      "4     Batteries      Batteries  \n",
      "Shape of the training data after dropping columns:\n",
      "(2886008, 4)\n"
     ]
    }
   ],
   "source": [
    "# Visualize the first few rows of the training data\n",
    "print(\"Training Data Sample:\")\n",
    "print(training_data.head())\n",
    "\n",
    "# drop columns name_y and Meta-Category2\n",
    "training_data = training_data.drop(columns=['name_y', 'Meta-Category2'], errors='ignore')\n",
    "\n",
    "print(\"Shape of the training data after dropping columns:\")\n",
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a1f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the date via tokenization and lemmatization\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def text_preprocessing_pipeline(text):\n",
    "    # Step 1: Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Step 2: Remove punctuation and numbers\n",
    "    tokens = [re.sub(r'[^a-zA-Z]', '', word) for word in tokens]  # Keep only letters\n",
    "    tokens = [word for word in tokens if word]  # Remove empty strings\n",
    "\n",
    "    # Step 3: Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Create a local copy of the training data\n",
    "training_data_copy = training_data.copy()\n",
    "\n",
    "# Apply the text preprocessing pipeline function to the 'category' and 'Meta-Category' columns (NOT APPLICABLE WITH CROSS-VALIDATION, VECTORIZATION IS HANDLED BELOW)\n",
    "training_data_copy['category'] = training_data_copy['category'].apply(text_preprocessing_pipeline)\n",
    "training_data_copy['Meta-Category'] = training_data_copy['Meta-Category'].apply(text_preprocessing_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7a5783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "  Mean Accuracy: 0.9984 (+/- 0.0001)\n",
      "  Individual Fold Scores: [0.9983524  0.99834547 0.99833507 0.99837318 0.99851871]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "  Mean Accuracy: 0.9996 (+/- 0.0001)\n",
      "  Individual Fold Scores: [0.99950451 0.99959806 0.99953916 0.99956514 0.99961019]\n",
      "\n",
      "Difference in Mean Accuracy: 0.0012\n",
      "\n",
      "==================================================\n",
      "DETAILED CROSS-VALIDATION RESULTS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "  Accuracy: 0.9984 (+/- 0.0001)\n",
      "  Precision_macro: 0.6335 (+/- 0.1132)\n",
      "  Recall_macro: 0.8987 (+/- 0.1627)\n",
      "  F1_macro: 0.6730 (+/- 0.1209)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\karel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.9996 (+/- 0.0001)\n",
      "  Precision_macro: 0.7121 (+/- 0.1288)\n",
      "  Recall_macro: 0.6941 (+/- 0.1252)\n",
      "  F1_macro: 0.7021 (+/- 0.1268)\n",
      "\n",
      "Class Distribution:\n",
      "Meta-Category\n",
      "Portable Electronics          2855705\n",
      "Connected Home Electronics      14000\n",
      "Batteries                       12071\n",
      "Office Supplies                  4223\n",
      "Pet Products                        6\n",
      "Kitchen Storage                     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total samples: 2886008\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your data is in training_data_copy\n",
    "X = training_data_copy['category']  # Features\n",
    "y = training_data_copy['Meta-Category']  # Target\n",
    "\n",
    "# Create pipelines (vectorization + model in one step)\n",
    "nb_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Use StratifiedKFold to maintain class distribution in each fold\n",
    "# With 111 samples, 5 folds gives ~22 samples per fold\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validate both models\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_scores = cross_val_score(nb_pipeline, X, y, cv=cv_strategy, scoring='accuracy')\n",
    "print(f\"Naive Bayes:\")\n",
    "print(f\"  Mean Accuracy: {nb_scores.mean():.4f} (+/- {nb_scores.std() * 2:.4f})\")\n",
    "print(f\"  Individual Fold Scores: {nb_scores}\")\n",
    "\n",
    "# Logistic Regression  \n",
    "logreg_scores = cross_val_score(logreg_pipeline, X, y, cv=cv_strategy, scoring='accuracy')\n",
    "print(f\"\\nLogistic Regression:\")\n",
    "print(f\"  Mean Accuracy: {logreg_scores.mean():.4f} (+/- {logreg_scores.std() * 2:.4f})\")\n",
    "print(f\"  Individual Fold Scores: {logreg_scores}\")\n",
    "\n",
    "# Compare the two\n",
    "print(f\"\\nDifference in Mean Accuracy: {abs(nb_scores.mean() - logreg_scores.mean()):.4f}\")\n",
    "\n",
    "# Optional: More detailed cross-validation with multiple metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Get multiple metrics at once\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DETAILED CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Naive Bayes detailed results\n",
    "nb_detailed = cross_validate(nb_pipeline, X, y, cv=cv_strategy, scoring=scoring)\n",
    "print(\"Naive Bayes:\")\n",
    "for metric in scoring:\n",
    "    scores = nb_detailed[f'test_{metric}']\n",
    "    print(f\"  {metric.capitalize()}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "# Logistic Regression detailed results  \n",
    "logreg_detailed = cross_validate(logreg_pipeline, X, y, cv=cv_strategy, scoring=scoring)\n",
    "print(\"\\nLogistic Regression:\")\n",
    "for metric in scoring:\n",
    "    scores = logreg_detailed[f'test_{metric}']\n",
    "    print(f\"  {metric.capitalize()}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nTotal samples: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea71be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and cross-validation saved succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained models and vectorizer via joblib for later use\n",
    "import joblib\n",
    "# Define the directory to save the models\n",
    "models_dir = current_dir / \"Models joblib\"\n",
    "\n",
    "joblib.dump(nb_pipeline, models_dir / 'naive_bayes_model_cv.joblib')\n",
    "joblib.dump(logreg_pipeline, models_dir / 'logistic_regression_model_cv.joblib')\n",
    "joblib.dump(cv_strategy, models_dir / 'cv_strategy.joblib')\n",
    "print(\"Models and cross-validation saved succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19bb023",
   "metadata": {},
   "source": [
    "From the results above, we can see that unfortunately cross-validation does not yield better results. By the nature of this dataset, it is too limited to properly train a classification model on. As next steps, we will consider a different approach of using an LLM to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
